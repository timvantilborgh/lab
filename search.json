[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Prof. Tim Vantilborgh",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nPost-hoc power analysis using cumulative probabilities of finding significance\n\n\n\n\n\n\nresearch methods\n\n\n\nA short tutorial on post-hoc power analysis\n\n\n\n\n\nJan 5, 2021\n\n\n5 min\n\n\n\n\n\n\n\nA VUB theme for xaringan presentations\n\n\n\n\n\n\npresentations\n\n\n\nFor those who would like to create Xaringan slides with a VUB theme\n\n\n\n\n\nDec 15, 2020\n\n\n1 min\n\n\n\n\n\n\n\nWorking from home during COVID-19 - Challenges and recommendations\n\n\n\n\n\n\ncovid-19\n\n\nevidence-based management\n\n\n\nA summary of our report on working from home during the COVID-19 pandemic\n\n\n\n\n\nNov 11, 2020\n\n\n6 min\n\n\n\n\n\n\n\nA more intuitive approach to effect sizes - Persons as effect sizes\n\n\n\n\n\n\nresearch methods\n\n\n\nA tutorial on using persons as effect sizes\n\n\n\n\n\nNov 11, 2020\n\n\n8 min\n\n\n\n\n\n\n\nFirst mini open science fair at Vrije Universiteit Brussel\n\n\n\n\n\n\nconferences\n\n\nopen science\n\n\n\nSome reflections on the first mini open science fair at the Vrije Universiteit Brussel.\n\n\n\n\n\nOct 24, 2019\n\n\n3 min\n\n\n\n\n\n\n\nWhy do we all use the same methods in Work and Organizational Psychology?\n\n\n\n\n\n\nconferences\n\n\nopen science\n\n\nresearch methods\n\n\n\nA reflection on the different methods used in our field\n\n\n\n\n\nJul 15, 2019\n\n\n6 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About",
    "section": "",
    "text": "Tim Vantilborgh is Full Professor at the Vrije Universiteit Brussel. He works in the Faculty of Psychology and Educational Sciences, where he is a member of the Work and Organizational Psychology research unit. He also works as an independent data science consultant as founder of e.videns."
  },
  {
    "objectID": "index.html#contact",
    "href": "index.html#contact",
    "title": "About",
    "section": "Contact",
    "text": "Contact\n\nEmail: tim.vantilborgh@vub.be"
  },
  {
    "objectID": "posts/210105-post-hoc-power/210105-post.html",
    "href": "posts/210105-post-hoc-power/210105-post.html",
    "title": "Post-hoc power analysis using cumulative probabilities of finding significance",
    "section": "",
    "text": "Conducting a power analysis can be difficult because you need a good estimate of the effect size that you want to be able to detect given a certain sample size and alpha level. Obtaining realistic estimates of effect sizes can be difficult when there is no prior research that looked at the same effect using a similar analytical approach. This issue becomes even more complex when you plan to use a more complicated analytical approach. Various tools exist when you want to estimate power for basic statistical techniques, such as regression or ANOVA, but when you are using more complicated techniques such as multilevel or structural equation models it becomes more difficult.\nAlternative approaches exist (e.g., Smallest Effect Size Of Interest - see Lakens, 2017 or sequential analysis - see Lakens, 2014) and you can always use simulation to estimate power (see Arend & Schäfer). However, these alternatives are not necessarily easy to implement. I was therefore intrigued when I read a new article by Bliese & Wang (2020) published in Journal of Management.\nIn this article, they explain how you can easily estimate post-hoc power by calculating the cumulative probability of finding significance. In essence, this cumulative probability tells you the probability of finding significant effects given the characteristics of your sample and model. The cumulative probability can be obtained in various ways:\n\nYou can use non-parametric bootstrapping and record for each bootstrap whether an effect was significant (1) or not (0), after which you calculate the percentage of significant effects accross all bootstrapped samples.\nYou can take the t or z value of your test, and calculate the cumulative probability directly. The formula for the t value is best used when sample sizes are small, but with samples of 100 observations or more you can use the formula for the z value. In R, this formula based on the z value is simply:\n\n1-pnorm(1.96-abs(X))\nwith X being the t or z value that is associated with your effect.\nBliese and Wang (2020) demonstrate how to use this approach in R, but this approach can be used with any type of analysis or software. To try it out for myself, I ran a simple structural equation model in Mplus. I use a dataset that contains 226 observations of 15 variables (the data and the scripts can be downloaded from OSF in the folder 210105 Post-hoc power analysis):\n\nItems 1 and 2 measure psychological contract fulfilment\nItems 3 tot 6 measure feelings of violation\nItems 7 to 15 measure trust\n\nI then estimated a structural equation model using the following code (see example.inp):\nTITLE: Demonstration post-hoc power\n\nDATA:\nFILE = \"dataset.txt\";\n\nVARIABLE:\nNAMES = fulf1 fulf2 viol1 viol2 viol3 viol4 \ntrust1 trust2 trust3 trust4 trust5 trust6 trust7 trust8 trust9;\nUSEV = fulf1 fulf2 viol1 viol2 viol3 viol4 trust1 trust2 trust3 trust4 trust5 trust6 trust7 trust8 trust9;\n\nANALYSIS:\n\nMODEL:\nfulfilment by fulf1 fulf2;\nviolation by viol1 viol2 viol3 viol4;\ntrust by trust1 trust2 trust3 trust4 trust5 trust6 trust7 trust8 trust9;\n\ntrust on violation fulfilment;\nviolation on fulfilment;\n\nOUTPUT:\nsampstat;\nIf you are familiar with Mplus, you will notice that this is a mediation model with three latent variables. The output file gives a lot of information (see example.out), but I will jump to what is probably the most important section, namely the effects of fulfilment on feelings of violation and trust and the effect of feelings of violation on trust.\nTRUST    ON\n    VIOLATION          0.397      0.208      1.912      0.056\n    FULFILMENT        -0.155      0.155     -1.005      0.315\n\n VIOLATIO ON\n    FULFILMENT        -0.260      0.053     -4.869      0.000\nThe first number in each line is the parameter estimate, the second number is the standard error, the third number of the ratio of the parameter estimate and the standard error (i.e., a z value), and the final number is the p-value. We will take these z values and use them in our formula (see R script example.R):\n1-pnorm(1.96-abs(1.912)) # Cumulative probability of violation on trust\n1-pnorm(1.96-abs(-1.005)) # Cumulative probability of fulfilment on trust\n1-pnorm(1.96-abs(-4.869)) # Cumulative probability of fulfilment on violation\nWe would find the following results:\n\nThe cumulative probability of the effect of feelings of violation on trust is .48. This would mean that there is a lot of uncertainty about this effect, which is no surprise as the p-value is just over .05. It would suggest that there is only 48% chance of finding a significant effect, given the characteristics of our sample and our model. Put differently, we have a power of 48% to find a significant effect, given our sample properties and model.\nThe cumulative probability of the effect of fulfilment on trust is .17. This suggests that finding a significant effect with a similar sample and model is very low. Put differently, we have a power of 17% to find a significant effect, given our sample properties and model.\nThe cumulative probability of fulfilment of violation is .998. The likelihood that we can replicate this effect, given the characteristics of our sample and model is extremely high. Put differently, we have a power of .998% to find a significant effect, given our sample properties and model.\n\nNow I know that post-hoc power analysis is a debated topic. But I think that this approach can be useful in some cases. Bliese and Wang mention several advantages of routinely reporting the cumulative probability. I think that an extra advantage is that you could use this approach if reviewers ask you to report a post-hoc power analysis (which is a question that I have received regularly in the past couple of years)."
  },
  {
    "objectID": "posts/201215-VUB-theme-xaringan/201215-post.html",
    "href": "posts/201215-VUB-theme-xaringan/201215-post.html",
    "title": "A VUB theme for xaringan presentations",
    "section": "",
    "text": "Lately, I have been using R to create presentations. In particular, I use the xaringan package to create html slides. Because there was no theme that fits the style of the Vrije Universiteit Brussel (VUB), I created a css file with a VUB theme. You can download the theme from my github page: https://github.com/timvantilborgh/VUB-theme-xaringan\n\nWhy would I want to use xaringan?\nCreating your slides in R with xaringan has a couple of benefits:\n\nYou don’t need to focus on the layout, and can focus on the content instead.\nYou can embed R code in the slides using code chunks. This means that you can integrate the output of analyses in your slides immediately. For example, you don’t need to copy-and-paste a correlation table into your powerpoint presentation, but just run the analysis and print the result in your R presentation.\nIf you work with git, then you have a proper version-control system for your slides.\nYou can use Latex in your presentation, meaning that you can easily work with formulas.\n\nGiven that I teach methodological courses, using R for my slides makes my life a lot easier.\nIf you want to see an example of xaringan slides in action (not with the VUB theme), check here"
  },
  {
    "objectID": "posts/190715-substantive-methodological-fit/190715-post.html",
    "href": "posts/190715-substantive-methodological-fit/190715-post.html",
    "title": "Why do we all use the same methods in Work and Organizational Psychology?",
    "section": "",
    "text": "“Oh god no… not another moderated mediation model”\n\nDuring several conferences the past years, I heard people silently uttering these words as they listened to a presentation. Even though I presented papers at conferences in which I used moderated mediation models myself, I could understand the sentiment. Many presentations at conferences resemble each other, because they use similar methods, designs, and analytical approaches. Not surprisingly, some conference attendants—including myself— started to grow bored of research that seemed to have reached a stalemate.\nDo we all use the same methods in Work and Organizational Psychology? Of course, there is variety—for one, we do not all use moderated mediation models. But that being said, there is some evidence suggesting that there is considerable methodological isomorphism in our field. For example, Casper and colleagues (2007) reviewed the work-family literature and documented the variety in research methods used. They showed that 89% of all studies used cross-sectional designs, 97% were field studies, and 89% were correlational studies. Longitudinal designs, experiments, and qualitative approaches were substantially underrepresented in the work-family literature. This situation is not limited to the work- family literature of course; it is likely that these problems emerge in other domains in Work and Organizational Psychology as well.\nThere are several reasons that could explain the existence of methodological isomorphism in our field. First, we tend to train PhD students in a limited set of research methods and analytical techniques. Most of the time, these methods and techniques are chosen because they are commonly used in the field, thus perpetuating the problem. Second, researchers may believe that using certain method may improve their chances of getting published. Third, reviewers acting as gatekeepers can be more critical of methods or techniques that they are not familiar with. As a result, manuscripts using non-traditional methods may have more difficulties getting published.\nOne might wonder if methodological isomorphism is problematic. After all, this may just reflect a field converging to set of methods that have proven their worth, with inferior methods no longer being used. Call it methodological evolution if you will. However, the methods and techniques that are commonly used are not necessarily optimal (e.g., cross- sectional designs are in many cases suboptimal). Moreover, methodological isomorphism may carry certain dangers. For one, it may lead to researchers choosing a research question that fits a certain method or technique, rather than picking the method which they believe is most appropriate for their research question. Moreover, by relying on a limited set of methods and analytical techniques, we may never fully come to understand workplace phenomena.\nWe discussed this issue of methodological isomorphism during the Future of Work and Organizational Psychology day at the 2019 EAWOP conference in Turin, Italy (http://eawop2019.org). The Future of Work and Organizational Psychology movement strives to build a better future for our field (https://www.futureofwop.com; click here for a manifesto on the future of WOP). We believe that our field can improve in several areas, including our research, our teaching, and the way that we organize academia. One of the workshops that we organized during the Future of Work and Organizational Psychology day focused on methods and aimed to tackle the issue of methodological isomorphism. We departed from the idea that we should use diverse methods and analyses to explore research questions if we want Work and Organizational Psychology to be a robust science (Grand et al., 2018).\nParticipants of the workshop took part in two exercises to come up with possible solutions to tackle the issue of methodological isomorphism. The result of this brainstorming exercise was a list of 9 actions (click here to see slides of workshop):\n\nUse existing platforms to stimulate collaboration and trust\nTackle your next research question with a group of people and multiple methods\nThink more thoroughly about research designs and consider applying multiple approaches\nEncourage mixed-methods research by creating a mixed-methods journal\nInvolve statisticians/methodologists as full partners in research projects\nTrain students in qualitative research methods and in assessing good qualitative research\nCreate an online platform to get feedback on study designs from the broad scientific community and to find potential collaborators\nCreate a community of methods experts, similar to Researchgate\nStart ManyLab type collaborations with multiple registered report studies that tackle a single research question using various methods\n\nWhat was striking to me during this workshop, was that participants acknowledged that we need more collaborations to tackle the issue of methodological isomorphism. In particular, substantive-methodological synergies should be established, meaning that substantive experts should ideally collaborate with methodological experts. However, we often lack the resources to start such collaborations. For example, we might not know who has expertise with a certain analytical approach or it may be necessary to develop trust before one can approach potential collaborators. In addition, it was clear that participants acknowledged that we should think more carefully about our research designs. Open science practices may help here: by submitting research as registered reports to journals, researchers get valuable feedback on their methods before data is collected. The list of journals that accept registered reports is growing, although the number of Work and Organizational Psychology journals on the list still remains fairly limited (click here for overview of journals that accept registered reports).\nThe Future of Work and Organizational Psychology initiative will try to use the actions that came out of this workshop as input to take further steps. In particular, we aim to take actions to stimulate substantive-methodological synergy in our field. This could be done by organizing workshops or summer schools in which researchers can be introduced to a broad variety of methods and that would allow substantive and methodological experts to meet each other. In addition, specific workshops could be set up in which we introduce researchers to registered reports and in which we stimulate collaborative registered reports. These collaborative registered reports consist of three stages. In the first stage, a research question is submitted to a platform and researchers can opt in to tackle this research question jointly. Next, a registered report application is written and submitted to a journal. These applications could include multiple approaches (e.g., qualitative approach, experimental approach, experience sampling approach) to address the same research question. Finally, data is collected following in-principle acceptance."
  },
  {
    "objectID": "posts/191024-mini-open-science-fair/191024-post.html",
    "href": "posts/191024-mini-open-science-fair/191024-post.html",
    "title": "First mini open science fair at Vrije Universiteit Brussel",
    "section": "",
    "text": "Yesterday, the Vrije Universiteit Brussel organised the first Mini Open Science Fair (click here to go to website). The event focused on researchers sharing their experiences with using various open science practices or tools. For example, I gave a brief presentation on the Open Science Framework (osf.io); I explained what the Open Science Framework allows you to do and how I used the website in my own research practices. The slides from my presentation can be downloaded from OSF (https://osf.io/uq9jk/).\nI really appreciated this event, as there aren’t that many initiatives in my university to promote open science. I decided to write this short blogpost to share some of the things that I learned during the event or that I found striking.\n\nThe event was organised for researchers from all possible disciplines, and it was refreshing to see how researchers from other disciplines approach open science. It’s easy to get caught up in the replication crisis in Psychology and forget that other disciplines have already discussed similar problems in the past. In many cases, other disciplines have even—sometimes succesfully—adopted their own solutions to deal with these issues. That being said, it was striking that the idea to preregister your research or to use registered reports was novel to many conference participants. Researchers working in Psychology appeared to be more aware of the use of preregistration and registered reports. Yet, these practices could be very relevant to other disciplines as well.\nI was surprised by the amount of platforms that are available to share and/or archive data. I used the Open Science Framework in the past, and I was aware that Zenodo existed as well (zenodo.org). However, I did not know that there are literally dozens of platforms that you can use. In fact, there is even a search engine to find the best platform for your needs: re3data.org.\nOne presenter (Wouter Ryckbosch, Twitter: @wryckbosch) talked about using citizen scientists for their research. Briefly put, they use volunteers to transcribe thousands of text fragments from the 18th and 19th century (https://www.getuigenissen.org/team?lang=en). I found the idea of using volunteers to help in research fascinating. Undoubtedly, this approach could also be used in psychological research, for example to watch and code video fragments. While using citizen scientists can also be challenging (e.g., recruiting and training volunteers can be a huge time investment), it can also speed up research and it can help to democratize research. Researchers interested in using citizen scientists can use zooniverse.org to set up a website for this."
  },
  {
    "objectID": "posts/201111-working-from-home-covid/201111-post.html",
    "href": "posts/201111-working-from-home-covid/201111-post.html",
    "title": "Working from home during COVID-19 - Challenges and recommendations",
    "section": "",
    "text": "This is a summary of the full report, which can be downloaded from: https://osf.io/9nxqv/\nLate October 2020, working from home became the norm again in Belgium to contain the spread of COVID-19. However, these measures require far-reaching efforts from both employees and employers and may have an impact on an individual, organizational and societal level. To sustain these measures, we need to look beyond the economic and health parameters. Work - and organizational psychological insights can help us to understand the challenges associated with working from home and inform evidence-based management practices.\n\nWorking from home or living at work?\nSince measures were imposed to manage the COVID-19 crisis, the number of Belgian employees working remotely at least one day a week increased from 16.9% to 62%. This constitutes a dramatic and sudden shift, where employees and employers who had no prior experience with remote working were suddenly forced to transition to virtual means of collaborating. The scientific literature shows that occasionally working from home can bestow several positive benefits to employees, such as a higher degree of autonomy, less work-family conflict, higher job satisfaction and performance, lower levels of stress, and a lower likelihood to quit their job.\nHowever, these benefits were observed when employees combined working from home with working at the office. This is in stark contrast with the situation today, as many employees are now working fulltime from home and as this remote work is mandated rather than a voluntary choice. As a result, employees may not experience the positive benefits mentioned above. While some studies show that certain groups of employees still experienced benefits from working from home during a lockdown, there is also a body of literature that suggests that there are various negative consequences such as:\n\nAn increase in work-family conflict because of work and family roles impeding each other\nLess opportunities to detach and recover from work because of blurring boundaries between work and other life domains\nWorking longer hours, skipping breaks and an increase in virtual meetings resulting in an intensification of work, less time to recover and feelings of exhaustion.\nFeelings of isolation, loneliness and decreased sense of connection due to the lack of social interaction\nA decrease in intrinsic motivation due to limited possibilities to fulfill the basic needs of employees (autonomy, connectedness and competence).\nDifficulties with performing tasks due to the extra time to coordinate and reorganize work, manage uncertainties, gather information and lack of necessary work resources.\nLack of communication and thus ambiguous expectations\nDifficulties communicating with and managing virtual teams as they require a different approach: transparent and clear communication, trust, moving away from micro-management and excessive control.\n\nThe above challenges require quite a lot from employers and employees. However, various actions can be taken to meet these challenges. Recommendations for employees:\n\nIf the epidemiological context allows it, it is recommended to find an optimal balance between working from home and working from the office. Two days of remote work per week are often recommended.\nTry to actively seek recovery from work. Research suggests that it can beneficial for recovery to actively invest time into finding an activity outside normal work (e.g., online workout classes, walking, social hours on video chat) that can help you to unwind from work.\nStructure your workday. Set a clear place and time for working from home, and use rituals to signal the start and the end of the workday. Don’t forget to include breaks in your work schedule.\n\nRecommendations for organizations and managers:\n\nManagers need to use compassionate and family-supportive leadership. This means that managers need to show empathy, attentive communication, a communal orientation, and vision-oriented leadership. Supervisors need to listen to employees’ concerns and acknowledge that each employee may be facing a uniquely different and difficult situation right now.\nOrganizations and managers need to clearly communicate what is expected from employees during this crisis. Essentially, this means that organizations need to fulfil the requirement listed in CAO85 to develop a formal telework policy, including a clear description about what to expect from teleworkers, e.g. in terms of accessibility and availability and means of communication.\nHelp employees in structuring their workday and creating a good office environment at home. Avoid creating the impression that employees should always be available. Be aware that many employees do not have a dedicated, equipped workspace at home. When employees lack a good office environment at home, organizations should facilitate setting up such a space by providing (the means to buy) office equipment such as an ergonomic chair, keyboard, stable internet connection, etcetera (e.g., by allowing employees to use these materials from the office).\nUse virtual communication tools to keep in touch with coworkers. Stay connected to each other by using virtual tools for informal get-togethers (e.g., a digital coffee break). Start or end formal virtual meetings by checking in on how everyone is doing. However, be aware that it is also important to not create additional obligations when employees are already strained (e.g., when they have kids at home). It is thus important to carefully balance the need for social interaction with overall workload.\nShow empathy and trust employees. Constantly controlling and monitoring remote workers undermines their sense of autonomy and reduces their wellbeing. Offer structure and support, provide clear goals, and try to regularly check-in on employees to see how they are doing. Make sure to create a psychologically safe environment, where employees feel at ease to share problems and concerns with supervisors or other staff members.\nAllow for flexibility and offer support. Be attentive to the unique needs of remote workers. Employees need to feel supported, meaning that the organization should demonstrate that they value their contributions and cares about their wellbeing.\nOffer training opportunities. Employees need to master new virtual communication and collaboration tools, which can cause stress. Organizations can reduce this stress by offering courses or workshops on how to use these new tools. Likewise, managing virtual teams can be a daunting task for supervisors. Training courses can help them to adjust their communication strategy and management style.\n\nAuthors: Prof. Tim Vantilborgh (lead author; VUB), Eva De Winter (VOCAP), Prof. Donatienne Desmette (UCL), Prof. Jonas Lang (UGent), Prof. Florence Stinglhamber (UCL), Prof. Anja Van den Broeck (KULeuven), Prof. Marijke Verbruggen (KULeuven)\nSupported by the Belgian Association of Psychological Sciences (BAPS), Vereniging voor Organisatie-, Consumenten, en Arbeidspsychologie (VOCAP), and the expert group on Corona and Psychology"
  },
  {
    "objectID": "posts/201201-persons-as-effect-sizes/201201-post.html",
    "href": "posts/201201-persons-as-effect-sizes/201201-post.html",
    "title": "A more intuitive approach to effect sizes - Persons as effect sizes",
    "section": "",
    "text": "Effect sizes are necessary to determine if an effect is substantial or not. For example, a correlation of .30 would often be considered a medium-sized effect (based on Cohen’s guidelines; whether these guidelines are useful is a different discussion…). An effect can be statistically significant, yet when the effect size is small one can wonder if the effect has any practical relevance. However, effect sizes are often difficult to interpret. What does it mean when a correlation signifies a small, medium, or large effect? How should you interpret various effect sizes, such as R2, []2, or f2?\nIn a recent article, Grice et al. (2020) propose a simple, intuitive effect size that is understandable by both researchers and the broader public https://journals.sagepub.com/doi/abs/10.1177/2515245920922982. Basically, they propose computing how many people in the study behaved or responded in a manner consistent with theoretical expectations. This can be computed as “percent correct classifications” (PCC). An interesting aspect of their approach is that describes the individuals rather than the inferences at the group-level, thus circumventing the ecological fallacy that we can infer how individuals behave based on group-level statistics.\nTo explore the idea behind the PCC effect size, I created a simple script in R with some simulated data and with a real data set. The R script https://osf.io/dnuq4?show=view&view_only= and the dataset https://osf.io/teqc2?show=view&view_only= can be downloaded from OSF.\nTo run the R script, make sure that you have the tidyverse and the faux package installed. We will use the faux package to simulate data.\n# Load libraries (install these first if you don't have them yet)\nlibrary(tidyverse)\nlibrary(faux)\n\nExample 1\nFor the first example, assume that we are doing a survey study with 100 participants in which we measure perceptions of psychological contract breach and feelings of violation. Psychological contract breach refers to the perception that an employee may have that her/his employer has failed to fulfil one or more obligations to her/him. Feelings of violation refer to negative emotions that may follow from breach perceptions, such as anger, frustration, and resentment. Theoretically, we expect a positive relationship between both variables: people who perceive a psychological contract breach will report stronger feelings of violation than people who do not perceive a psychological contract breach. Let’s use the faux package to simulate some data on both variables, assuming that the means of both variables are equal to 3, the standard deviations are equal to 1, and the correlation between both variables is 0.\n# Generate data\ndf &lt;- rnorm_multi(n = 100,\n                  mu = c(3, 3),\n                  sd = c(1, 1),\n                  r = c(0),\n                  varnames = c(\"breach\", \"violation\"),\n                  empirical = FALSE)\nThe next step to get the PCC effect size is dichotomizing both variables with a median split. While there are obvious problems with a median split (which are discussed in the article), this should work when the variables are normally distributed.\n# Perform median split on both variables\ndf$breach.dichotomized = if_else(df$breach &lt; median(df$breach), \"low\", \"high\")\ndf$violation.dichotomized = if_else(df$violation &lt; median(df$violation), \"low\", \"high\")\nTheoretically, we expect that respondents who are categorized as “high” on the dichotomous breach variable will also be categorized as “high” on the dichotomous violation variable. And we would expect that respondents who are categorized as “low” on the dichotomous breach variable will also be categorized as “low” on the dichotomous violation variable. Whenever such a combination is observed, we can describe this respondent as correctly classified. Whenever there is a different combination of both dichotomous variables (e.g., “low” breach and “high” feelings of violation), it is inconsistent with our theoretical prediction and we count it as incorrectly classified.\nSo, to get the PCC effect size, we will compute a cross-table with the percentage of cases for each combination of the two dichotomous variables. Based on this, we can compute the percentage correctly classified and the percentage incorrectly classified.\n# Create cross-table\nproportions = prop.table(table(df$breach.dichotomized, df$violation.dichotomized))\ncorrectly.classified = proportions[1,1] + proportions[2,2]\nincorrectly.classified = proportions[1,2] + proportions[2,1]\nIn this case, we would find that 50% of all respondents are correctly classified and 50% are incorrectly classified. Put differently, 50% follows the theoretical expectations which seems to be equal to chance (not surprising as the correlation between both variables was set to 0).\n\n\nExample 2\nLet’s run the same example, but change the correlation between both variables to 0.5 (a strong effect size according to Cohen’s guidelines).\n# Generate data\ndf &lt;- rnorm_multi(n = 100,\n                   mu = c(3, 3),\n                   sd = c(1, 1),\n                   r = c(0.5),\n                   varnames = c(\"breach\", \"violation\"),\n                   empirical = FALSE)\n\n# Perform median split on both variables\ndf$breach.dichotomized = if_else(df$breach &lt; median(df$breach), \"low\", \"high\")\ndf$violation.dichotomized = if_else(df$violation &lt; median(df$violation), \"low\", \"high\")\n\n# Create cross-table\nproportions = prop.table(table(df$breach.dichotomized, df$violation.dichotomized))\ncorrectly.classified = proportions[1,1] + proportions[2,2]\nincorrectly.classified = proportions[1,2] + proportions[2,1]\nRunning this code would yield 66% correctly classified cases and 34% incorrectly classified cases (note that your results may differ somewhat because of the randomly simulated data). This is intuitively understandable: about 2/3rd of all participants seem to (report to) behave in line with what we theoretically expect.\n\n\nExample 3\nLet’s simulate data one more time, but now we will use a correlation with a whopping magnitude of .90 and see what happens with the PCC effect size.\n# Generate data\ndf &lt;- rnorm_multi(n = 100,\n                  mu = c(3, 3),\n                  sd = c(1, 1),\n                  r = c(0.9),\n                  varnames = c(\"breach\", \"violation\"),\n                  empirical = FALSE)\n\n# Perform median split on both variables\ndf$breach.dichotomized = if_else(df$breach &lt; median(df$breach), \"low\", \"high\")\ndf$violation.dichotomized = if_else(df$violation &lt; median(df$violation), \"low\", \"high\")\n\n# Create cross-table\nproportions = prop.table(table(df$breach.dichotomized, df$violation.dichotomized))\ncorrectly.classified = proportions[1,1] + proportions[2,2]\nincorrectly.classified = proportions[1,2] + proportions[2,1]\nWe now have 84% correctly classified respondents and 16% incorrectly classified respondents. Put differently, more than 4/5th of the sample (reports to) behave(s) in line with our theoretical expectations. Again, this is more easy to understand than saying that there is a “very strong correlation” between both variables.\n\n\nExample 4: Real data\nOk, let’s use real data for the final example. The data set “data_example_pcc.csv” contains real data from a survey in which breach perceptions and feelings of violation were measured. The dataset is rather small (53 observations), but it serves the purpose of demonstrating the PCC effect size. We will start by reading in the data and estimating the correlation between both variables.\ndf = read_csv2(\"data_example_pcc.csv\")\n\n# Correlation\ncor.test(df$breach, df$violation)\nThe correlation between both variables is .36 (a medium sized effect) and is statistically significant (p = .012).\nPearson's product-moment correlation\n\ndata:  df$breach and df$violation\nt = 2.6038, df = 45, p-value = 0.01245\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.08333751 0.58792082\nsample estimates:\n      cor \n0.3618447 \nWe will use the same approach as with the simulated data:\n# Perform median split on both variables\ndf$breach.dichotomized = if_else(df$breach &lt; median(df$breach, na.rm=T), \"low\", \"high\")\ndf$violation.dichotomized = if_else(df$violation &lt; median(df$violation, na.rm=T), \"low\", \"high\")\n\n# Create cross-table\nproportions = prop.table(table(df$breach.dichotomized, df$violation.dichotomized))\ncorrectly.classified = proportions[1,1] + proportions[2,2]\nincorrectly.classified = proportions[1,2] + proportions[2,1]\nWe find that 61.70% of all participants are correctly classified. This does not appear to be a very strong effect, as it means that 38.30% of the participants report behaving in a way that is inconsistent with theory (e.g., perceiving a breach but not experiencing any feelings of violation or perceiving no breach but still experiencing feelings of violation).\nOverall, I feel that the PCC effect size has a certain appeal. It is an easy way to express the strength of an effect to a broader audience. You don’t need to understand statistics to intuitively understand the PCC values. The examples that I use here are all based on a simple correlation, but the article also describes how the PCC can be used to estimate effect sizes in experimental designs or when assessing risk. Moreover, it also describes how the PCC can be used to understand the data behind the inferences."
  },
  {
    "objectID": "evidens.html",
    "href": "evidens.html",
    "title": "e.videns data science consultancy",
    "section": "",
    "text": "As a researcher, I have a lot of experience in collecting, analyzing, and interpreting data. I can help you with a variety of data-related tasks, including:\n\nDeveloping and testing surveys\nRunning statistical analyses\nBuilding predictive models\nRunning segmentation analyses\nGiving advice on how to run a survey study\n\nMy expertise lies in the field of organizational behavior, but I am open to working on projects in other fields as well. In partilcular, I have experience with the following statistical techniques and methodological designs:\n\nStructural equation modeling\nHierarchical linear modeling\nLatent class analysis\nNetwork analysis\nMachine learning\nMultilevel models\nPsychometric analyses\nExperimental designs\nLongitudinal designs\nExperience sampling designs"
  },
  {
    "objectID": "evidens.html#what-do-i-do",
    "href": "evidens.html#what-do-i-do",
    "title": "e.videns data science consultancy",
    "section": "",
    "text": "As a researcher, I have a lot of experience in collecting, analyzing, and interpreting data. I can help you with a variety of data-related tasks, including:\n\nDeveloping and testing surveys\nRunning statistical analyses\nBuilding predictive models\nRunning segmentation analyses\nGiving advice on how to run a survey study\n\nMy expertise lies in the field of organizational behavior, but I am open to working on projects in other fields as well. In partilcular, I have experience with the following statistical techniques and methodological designs:\n\nStructural equation modeling\nHierarchical linear modeling\nLatent class analysis\nNetwork analysis\nMachine learning\nMultilevel models\nPsychometric analyses\nExperimental designs\nLongitudinal designs\nExperience sampling designs"
  },
  {
    "objectID": "evidens.html#examples-of-my-work",
    "href": "evidens.html#examples-of-my-work",
    "title": "e.videns data science consultancy",
    "section": "Examples of my work",
    "text": "Examples of my work\nIn the past, I have worked on a variety of projects, including:\n\nDeveloping and testing an instrument to measure employee engagement\nDeveloping, running, and analyzing a survey on well-being of employees\nRunning segmentation analysis to identify different types of clients and building a predictive model using machine learning to predict segment membership for new clients"
  },
  {
    "objectID": "evidens.html#rates",
    "href": "evidens.html#rates",
    "title": "e.videns data science consultancy",
    "section": "Rates",
    "text": "Rates\nI work with a fixed rate. The intake meeting is free of charge. Subsequently, I will provide you with a quote based on the complexity of the project and the number of hours I expect to spend on it."
  },
  {
    "objectID": "evidens.html#contact-us",
    "href": "evidens.html#contact-us",
    "title": "e.videns data science consultancy",
    "section": "Contact us",
    "text": "Contact us\nFor more information, please contact us at tim.vantilborgh@vub.be."
  }
]